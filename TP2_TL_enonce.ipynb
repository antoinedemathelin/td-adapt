{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d928959d",
   "metadata": {},
   "source": [
    "<h1>Supervised Transfer Learning tutorial : parameter-based approaches </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b1745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "import pandas as pd\n",
    "import  numpy as np\n",
    "import sklearn.metrics as metr\n",
    "import sklearn.model_selection as select\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import adapt._tree_utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae5f5d7",
   "metadata": {},
   "source": [
    "<h2>Exercise 1 : Transfer on Linear Regression </h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87662265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(x,beta=2,noise=0.1):\n",
    "    return beta*x + noise * np.random.randn(len(x))\n",
    "\n",
    "def gaussian(x, mu=0., s=1.):\n",
    "    return 1./np.sqrt( 2. * np.pi * s**2 ) * np.exp( -(x-mu)**2 / ( 2. * s**2 ) )\n",
    "\n",
    "np.random.seed(0)\n",
    "mu_s = 0\n",
    "sigma = 1\n",
    "beta = 2\n",
    "var=0.5\n",
    "epsilon = var*np.random.randn(1)[0]\n",
    "\n",
    "Xs = np.random.randn(100) * sigma + mu_s\n",
    "Xt_all = np.random.randn(100) * sigma + mu_s \n",
    "\n",
    "n_train = 5\n",
    "Xt = Xt_all[:n_train]\n",
    "ys = label_func(Xs,beta=beta,noise=0.5)\n",
    "yt_all = label_func(Xt_all,beta=beta+abs(epsilon),noise=0.5)\n",
    "yt = yt_all[:n_train]\n",
    "# Warning : we will use only Xt,yt as training data but Xt_all,yt_all to assess performance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892bcd92",
   "metadata": {},
   "source": [
    "### Question 1.1 : Formalize the transfer learning problem\n",
    "First plot Source and Target data.\n",
    "\n",
    "Write $P_S(X)$ and $P_T(X)$\n",
    "\n",
    "Here we have a $\\beta_S,\\beta_T$ parameters controlling respectively Source and Target distributions.\n",
    "Both present the same noise we note $\\sigma$.\n",
    "\n",
    "Express $P_S(Y/X=x)$ and $P_T(Y/X=x)$ in function of these parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4044156",
   "metadata": {},
   "source": [
    "### Question 1.2 : \n",
    "\n",
    "We can note $\\beta_T = \\beta_S+ |\\epsilon|$.\n",
    "Express the distribution $P(\\epsilon)$ depending on its mean and standard deviation $\\mu_\\epsilon,\\sigma_\\epsilon$.\n",
    "What is the mean expected value of $\\mathbb{E}[\\beta_S+ \\epsilon]$ ? Is it the same as $\\mathbb{E}[\\beta_T]$ ?\n",
    "                                                                                                   \n",
    "(Bonus) Write the formula corresponding to $\\mathbb{E}[Y|X=x]$.\n",
    "                                                                                                   \n",
    "Is this a Covariate Shift situation ? Why ?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a94191",
   "metadata": {},
   "source": [
    "### Question 1.3 : Parameter-based transfer on linear model\n",
    "\n",
    "Train a linear regression model on Source only and another linear regression model on Target only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5609ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from adapt.parameter_based import RegularTransferLR\n",
    "\n",
    "def mse(y1,y2):\n",
    "    return np.mean(np.square(y1 - y2))\n",
    "\n",
    "    \n",
    "source_model = #...\n",
    "source_model.fit(Xs.reshape(-1, 1), ys)\n",
    "\n",
    "only_tgt_model = #...\n",
    "only_tgt_model.fit(Xt.reshape(-1, 1), yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a514ff",
   "metadata": {},
   "source": [
    "### Question 1.4 : \n",
    "Transfer Source model using Target data and `RegularTransferLR` algorithm.\n",
    "\n",
    "Write the optimization problem solved by this algorithm (see course or documentation).\n",
    "What is the role of `lambda_` parameter ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabece4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_model = RegularTransferLR(source_model, lambda_=1.)\n",
    "tgt_model.fit(Xt.reshape(-1, 1), yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ee3f13",
   "metadata": {},
   "source": [
    "### Question 1.5 : Compare performance of these three linear regressors\n",
    "Is the score provided equal to $1 - mse$ (mean squared error)? Why ?\n",
    "\n",
    "We note $\\widehat{\\beta_S},\\widehat{\\beta_T},\\widehat{\\beta_{transf}}$ parameters estimated by these regressors.\n",
    "Express these two printed performance measures in function of these estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e170eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions of source model on source data:\n",
    "yps = source_model.predict(Xs.reshape(-1, 1))  \n",
    "err_src = np.mean(np.square(yps - ys))\n",
    "\n",
    "#Predictions of target only linear model on target data:\n",
    "ypt_only = #...\n",
    "err_tgt_only = #...\n",
    "\n",
    "#Predictions of transferred linear model on target data:\n",
    "ypt = #....\n",
    "err_tgt = #...\n",
    "\n",
    "print(\"Source average squared error : %.4f\"%err_src)\n",
    "print(\"Target only average squared error : %.4f\"%err_tgt_only)\n",
    "print(\"Target average squared error : %.4f\"%err_tgt)\n",
    "\n",
    "print(\"Source average score : %.4f\"%source_model.score(Xs.reshape(-1, 1), ys))\n",
    "print(\"Target only average score : %.4f\"%only_tgt_model.score(Xt.reshape(-1, 1), yt))\n",
    "print(\"Target average score : %.4f\"%tgt_model.score(Xt.reshape(-1, 1), yt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0c5c0",
   "metadata": {},
   "source": [
    "### Question 2.1 : \n",
    "Write a python function to repeat the experiment with various values of `lambda_`, `var` and various amount of training data.\n",
    "\n",
    "Add performance assessment of source model on target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1045280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_mse(var=1,lambda_=1,n_train=10,n_exp=10):\n",
    "    err_src = np.zeros(n_exp)\n",
    "    err_src_only = np.zeros(n_exp)\n",
    "    err_tgt = np.zeros(n_exp)\n",
    "    err_tgt_only = np.zeros(n_exp)\n",
    "    \n",
    "    for i in range(n_exp):\n",
    "        \"\"\"\n",
    "        #...............\n",
    "        \"\"\"\n",
    "        \n",
    "        err_src[i] = mse(source_model.predict(Xs.reshape(-1,1)),ys)\n",
    "        err_src_only[i] = mse(source_model.predict(Xt_all.reshape(-1,1)),yt_all)\n",
    "        err_tgt_only[i] = mse(only_tgt_model.predict(Xt_all.reshape(-1,1)),yt_all)\n",
    "        err_tgt[i] = mse(tgt_model.predict(Xt_all.reshape(-1,1)),yt_all)\n",
    "\n",
    "    return np.mean(err_src),np.mean(err_src_only),np.mean(err_tgt),np.mean(err_tgt_only)\n",
    "\n",
    "def experiment_score(var=1,lambda_=1,n_train=10,n_exp=10):\n",
    "    score_src = np.zeros(n_exp)\n",
    "    score_src_only = np.zeros(n_exp)\n",
    "    score_tgt = np.zeros(n_exp)\n",
    "    score_tgt_only = np.zeros(n_exp)\n",
    "    \n",
    "    for i in range(n_exp):\n",
    "        \"\"\"\n",
    "        #...............\n",
    "        \"\"\"\n",
    "\n",
    "    return np.mean(score_src),np.mean(score_src_only),np.mean(score_tgt),np.mean(score_tgt_only)\n",
    "\n",
    "err_src,err_src_only,err_tgt,err_tgt_only = experiment_mse(var=0.5,lambda_=1,n_train=5,n_exp=100)\n",
    "score_src,score_src_only,score_tgt,score_tgt_only = experiment_score(var=0.5,lambda_=1,n_train=5,n_exp=100)\n",
    "\n",
    "print(\"Source average squared error : %.4f\"%err_src)\n",
    "print(\"Source only average squared error : %.4f\"%err_src_only)\n",
    "print(\"Target only average squared error : %.4f\"%err_tgt_only)\n",
    "print(\"Target average squared error : %.4f\"%err_tgt)\n",
    "\n",
    "print(\"Source average score : %.4f\"%score_src)\n",
    "print(\"Source only average score : %.4f\"%score_src_only)\n",
    "print(\"Target only average score : %.4f\"%score_tgt_only)\n",
    "print(\"Target average score : %.4f\"%score_tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b6d60f",
   "metadata": {},
   "source": [
    "### Question 2.2: \n",
    "\n",
    "What seems to be the best value for `lambda_` ?\n",
    "Try independently `n_train=50` and `lambda_=3`, `lambda_=10` and `var=2` \n",
    "What can you observe ?\n",
    "\n",
    "Try to change $\\epsilon$ random variable for an uniform distribution.\n",
    "What are your observations ?\n",
    "\n",
    "In which conditions this transfer approach is usefull ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3293d8a",
   "metadata": {},
   "source": [
    "### (Bonus) Question 3 : \n",
    "Express the closed-form of $\\widehat{ \\beta_{transf} }$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71776f2d",
   "metadata": {},
   "source": [
    "<h2>Exercise 2 : Transfer on Decision Trees (on synthetic data)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da0f487",
   "metadata": {},
   "source": [
    "<h3>1. Classification of Gaussian clusters </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6fd2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_s_0 = np.array([-1,0])\n",
    "mean_s_1 = np.array([1,0])\n",
    "mean_t_0 = np.array([-1,0])\n",
    "mean_t_1 = np.array([0,0])\n",
    "\n",
    "sig_s_0 = np.diag([1,1])\n",
    "sig_s_1 = np.diag([1,1])\n",
    "sig_t_0 = np.diag([2,2])\n",
    "sig_t_1 = np.diag([2,2])\n",
    "\n",
    "size=100\n",
    "ns_0 = size//2\n",
    "nt_0 = size//2\n",
    "\n",
    "Xs_0 = np.random.multivariate_normal(mean_s_0, sig_s_0, size=ns_0)\n",
    "Xs_1 = np.random.multivariate_normal(mean_s_1, sig_s_1, size=size-ns_0)\n",
    "\n",
    "Xt_0 = np.random.multivariate_normal(mean_t_0, sig_t_0, size=nt_0)\n",
    "Xt_1 = np.random.multivariate_normal(mean_t_1, sig_t_1, size=size-nt_0)\n",
    "\n",
    "Xs = np.r_[Xs_0,Xs_1]\n",
    "Xt = np.r_[Xt_0,Xt_1]\n",
    "\n",
    "ys = np.zeros(size)\n",
    "ys[ns_0:] = 1\n",
    "yt = np.zeros(size)\n",
    "yt[nt_0:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f88ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(6, 3))\n",
    "ax[0].scatter(Xs[:ns_0, 0], Xs[:ns_0, 1],marker='o',edgecolor='black',color='blue',label='class 0')\n",
    "ax[0].scatter(Xs[ns_0:, 0], Xs[ns_0:, 1],marker='o',edgecolor='black',color='red',label='class 1')\n",
    "ax[0].set_title('Source data')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].scatter(Xt[:nt_0, 0], Xt[:nt_0, 1],marker='o',edgecolor='black',color='blue',label='class 0')\n",
    "ax[1].scatter(Xt[nt_0:, 0], Xt[nt_0:, 1],marker='o',edgecolor='black',color='red',label='class 1')\n",
    "ax[1].set_title('Target data')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a1212b",
   "metadata": {},
   "source": [
    "### Question 1.1 :\n",
    "Express $P_S(X|Y=y)$ and $P_T(X|Y=y)$.\n",
    "What kind of transformation does this represent ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463510c9",
   "metadata": {},
   "source": [
    "### Question 1.2 :\n",
    "How can we change parameters to get a Target shift situation ?\n",
    "\n",
    "Train linear SVM classification models both on Source and Target and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55087b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_source = SVC(kernel='linear')\n",
    "\n",
    "#...\n",
    "#...\n",
    "#..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2477945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code plots the Source decision function on Source and Target data\n",
    "\n",
    "plot_step = 0.1\n",
    "x_min, x_max = Xt[:, 0].min() - 1, Xt[:, 0].max() + 1\n",
    "y_min, y_max = Xt[:, 1].min() - 1, Xt[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "#Source decision function:\n",
    "ypred_src = clf_source.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "ypred_src = ypred_src.reshape(xx.shape)\n",
    "    \n",
    "fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(6, 3))\n",
    "ax[0].scatter(Xs[:ns_0, 0], Xs[:ns_0, 1],marker='o',edgecolor='black',color='blue',label='class 0')\n",
    "ax[0].scatter(Xs[ns_0:, 0], Xs[ns_0:, 1],marker='o',edgecolor='black',color='red',label='class 1')\n",
    "\n",
    "ax[0].contourf(xx, yy, ypred_src, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "ax[0].set_title('Source data')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].scatter(Xt[:nt_0, 0], Xt[:nt_0, 1],marker='o',edgecolor='black',color='blue',label='class 0')\n",
    "ax[1].scatter(Xt[nt_0:, 0], Xt[nt_0:, 1],marker='o',edgecolor='black',color='red',label='class 1')\n",
    "\n",
    "ax[1].contourf(xx, yy, ypred_src, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "ax[1].set_title('Target data')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf04842",
   "metadata": {},
   "source": [
    "### Question 1.3 :\n",
    "Draw, similarly to the previous, plot the target decision function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91effc",
   "metadata": {},
   "source": [
    "### Question 1.4:\n",
    "\n",
    "Write a $KL(P_S^0,P_S^1,P_T^0,P_T^1)$ that returns Kullback-Leibler divergence betwwen source and target class proportions.\n",
    "\n",
    "Compute it both on \"right\" and \"left\" of the linear SVM classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e279cc",
   "metadata": {},
   "source": [
    "### Question 1.5:\n",
    "\n",
    "Write a divergence gain function that computes the gain acquired by the linear SVM classifier (see course)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcc4909",
   "metadata": {},
   "source": [
    "### (Bonus) Question 1.6 :\n",
    "\n",
    "Suppose $Q_1 \\sim  \\mathcal{N}(\\mu_1,\\sigma_1)$ and $Q_2 \\sim  \\mathcal{N}(\\mu_2,\\sigma_2)$,\n",
    "\n",
    "Prove that $KL[ Q_1 || Q_2] = \\frac{1}{2}\\left( \\frac{(\\mu_2 - \\mu_1)^2}{\\sigma_2^2} + \\frac{\\sigma_1^2}{\\sigma_2^2} -\\ln{\\frac{\\sigma_1^2}{\\sigma_2^2}} - 1 \\right)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f52166",
   "metadata": {},
   "source": [
    "<h3>2. Sum of Gaussian clusters and decision tree classifiers </h3>\n",
    "Now we will experiment several basic transformations between Gaussian distributions with several clusters per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e84491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_N_clusters(N,class_,mean_range=[-2,2],sig_range=[0.5,2]):\n",
    "    classes = np.repeat(class_,N)\n",
    "    means = np.zeros(N,dtype=object)\n",
    "    sigs = np.zeros(N,dtype=object)\n",
    "    for k in range(N):\n",
    "        means[k]=np.random.uniform(low=mean_range[0], high=mean_range[1], size=2)\n",
    "        sigs[k]=np.diag(np.random.uniform(low=sig_range[0], high=sig_range[1], size=2))\n",
    "    return means,sigs,classes\n",
    "\n",
    "def create_clusters(N0,N1,mean_range=[-2,2],sig_range=[0.5,2]):\n",
    "    means_0,sigs_0,classes_0=create_N_clusters(N0,0,mean_range=mean_range,sig_range=sig_range)\n",
    "    means_1,sigs_1,classes_1=create_N_clusters(N1,1,mean_range=mean_range,sig_range=sig_range)\n",
    "    \n",
    "    means = np.concatenate((means_0,means_1))\n",
    "    sigs = np.concatenate((sigs_0,sigs_1))\n",
    "    classes = np.concatenate((classes_0,classes_1))\n",
    "    return means,sigs,classes\n",
    "\n",
    "def translate_N_clusters(N,means,sigs,classes,mean_range=[-2,2],sig_range=[0.5,2]):\n",
    "    indexes = np.random.choice(classes.size,size=N,replace=False)\n",
    "    for k in indexes:\n",
    "        means[k]=np.random.uniform(low=mean_range[0], high=mean_range[1], size=2) \n",
    "    return means,sigs,classes\n",
    "\n",
    "def shrink_N_clusters(N,means,sigs,classes,mean_range=[-2,2],sig_range=[0.5,2]):\n",
    "    indexes = np.random.choice(classes.size,size=N,replace=False)\n",
    "    for k in indexes:\n",
    "        sigs[k]=np.diag(np.random.uniform(low=sig_range[0], high=sig_range[1], size=2))  \n",
    "    return means,sigs,classes\n",
    "\n",
    "def delete_N_clusters(N,means,sigs,classes,mean_range=[-2,2],sig_range=[0.5,2]):\n",
    "    indexes = np.random.choice(classes.size,size=N,replace=False)\n",
    "    return np.delete(means,indexes,axis=0),np.delete(sigs,indexes,axis=0),np.delete(classes,indexes,axis=0)\n",
    "\n",
    "def add_N_clusters(N,class_,means,sigs,classes,mean_range=[-2,2],sig_range=[0.5,2]):\n",
    "    new_means,new_sigs,new_classes=create_N_clusters(N,class_,mean_range=mean_range,sig_range=sig_range)\n",
    "    means = np.concatenate((means,new_means))\n",
    "    sigs = np.concatenate((sigs,new_sigs))\n",
    "    classes = np.concatenate((classes,new_classes))\n",
    "    return means,sigs,classes\n",
    "\n",
    "def generate_samples(n_by_cluster,means,sigs,classes):\n",
    "    for k,c in enumerate(classes):\n",
    "        X_ = np.random.multivariate_normal(means[k], sigs[k], size=n_by_cluster)\n",
    "        y_ = np.repeat(c,n_by_cluster)\n",
    "        if k == 0:\n",
    "            X = X_\n",
    "            y = y_\n",
    "        else:\n",
    "            X = np.r_[X,X_]\n",
    "            y = np.r_[y,y_]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d030fe3e",
   "metadata": {},
   "source": [
    "### Translations between Source and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c05241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "N0=5\n",
    "N1=5\n",
    "means,sigs,classes = create_clusters(N0,N1,mean_range=[-5,5],sig_range=[0.5,2])\n",
    "Xs,ys=generate_samples(100,means,sigs,classes)\n",
    "#Translation:\n",
    "means,sigs,classes = translate_N_clusters(2,means,sigs,classes,mean_range=[-5,5],sig_range=[0.5,2])\n",
    "Xt,yt=generate_samples(100,means,sigs,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf001a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(6, 3))\n",
    "ax[0].scatter(Xs[np.where(ys==0)[0], 0], Xs[np.where(ys==0)[0], 1],marker='o',edgecolor='black',color='blue',label='class 0')\n",
    "ax[0].scatter(Xs[np.where(ys==1)[0], 0], Xs[np.where(ys==1)[0], 1],marker='o',edgecolor='black',color='red',label='class 1')\n",
    "ax[0].set_title('Source data')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].scatter(Xt[np.where(yt==0)[0], 0], Xt[np.where(yt==0)[0], 1],marker='o',edgecolor='black',color='blue',label='class 0')\n",
    "ax[1].scatter(Xt[np.where(yt==1)[0], 0], Xt[np.where(yt==1)[0], 1],marker='o',edgecolor='black',color='red',label='class 1')\n",
    "ax[1].set_title('Target data')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076b3b3e",
   "metadata": {},
   "source": [
    "### Question 2.1 : Source and Target decision trees.\n",
    "\n",
    "Train both Source and Target decision tree classification models and assess them using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad8908",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_source_by_c = 50\n",
    "n_target_by_c = 10\n",
    "\n",
    "means_src,sigs_src,classes_src = create_clusters(N0,N1,mean_range=[-5,5],sig_range=[0.5,2])\n",
    "\n",
    "\n",
    "Xs,ys=generate_samples(n_source_by_c,means_src,sigs_src,classes_src)\n",
    "#Translation:\n",
    "means,sigs,classes = translate_N_clusters(2,means_src,sigs_src,classes_src,mean_range=[-5,5],sig_range=[0.5,2])\n",
    "Xt,yt=generate_samples(n_target_by_c,means,sigs,classes)\n",
    "\n",
    "MAX = 5\n",
    "K_FOLD = 10\n",
    "\n",
    "# Source and Target classifiers :\n",
    "clf_source = DecisionTreeClassifier(max_depth=MAX)\n",
    "clf_target = DecisionTreeClassifier(max_depth=MAX)\n",
    "\n",
    "\n",
    "#K folds coss-validation:\n",
    "skf = select.StratifiedKFold(n_splits=K_FOLD)\n",
    "\n",
    "score_src = np.zeros(K_FOLD)\n",
    "score_src_tgt = np.zeros(K_FOLD)\n",
    "score_tgt_src = np.zeros(K_FOLD)\n",
    "score_tgt = np.zeros(K_FOLD)\n",
    "\n",
    "k=0\n",
    "for train, test in skf.split(Xs, ys):\n",
    "    X_src_train, Y_src_train, X_src_test, Y_src_test = Xs[train], ys[train], Xs[test], ys[test]\n",
    "    \n",
    "    #...\n",
    "\n",
    "    k+=1\n",
    "\n",
    "k=0\n",
    "for train, test in skf.split(Xt, yt):\n",
    "    X_tgt_train, Y_tgt_train, X_tgt_test, Y_tgt_test = Xt[train], yt[train], Xt[test], yt[test]\n",
    "\n",
    "    #...\n",
    "\n",
    "    k+=1\n",
    "    \n",
    "print('Score Target model: {:.3f}'.format(np.mean(score_tgt)))\n",
    "print('Score Source model: {:.3f}'.format(np.mean(score_src)))\n",
    "print('Score Source model on Target: {:.3f}'.format(np.mean(score_src_tgt)))\n",
    "#print('Score Target model on Source: {:.3f}'.format(np.mean(score_tgt_src)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333c31a0",
   "metadata": {},
   "source": [
    "### Question 2.2 : Parameter-based transfer on Decision Trees\n",
    "\n",
    "Using source model and target data, train STRUT and SER decision tree classification models and assess them using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18150072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapt.parameter_based import TransferTreeClassifier, TransferForestClassifier\n",
    "import copy\n",
    "\n",
    "clf_src = copy.deepcopy(clf_source)\n",
    "\n",
    "strut_model = TransferTreeClassifier(estimator=clf_src,algo=\"strut\")\n",
    "ser_model = TransferTreeClassifier(estimator=clf_src,algo=\"ser\")\n",
    "\n",
    "score_strut= np.zeros(K_FOLD)\n",
    "score_ser = np.zeros(K_FOLD)\n",
    "\n",
    "k=0\n",
    "for train, test in skf.split(Xt, yt):\n",
    "    X_tgt_train, Y_tgt_train, X_tgt_test, Y_tgt_test = Xt[train], yt[train], Xt[test], yt[test]\n",
    "    strut_model.fit(X_tgt_train, Y_tgt_train)\n",
    "    ser_model.fit(X_tgt_train, Y_tgt_train)\n",
    "    score_strut[k] = strut_model.score(X_tgt_test, Y_tgt_test)\n",
    "    score_ser[k] = ser_model.score(X_tgt_test, Y_tgt_test)\n",
    "\n",
    "    k+=1\n",
    "\n",
    "print('Score STRUT model: {:.3f}'.format(np.mean(score_strut)))\n",
    "print('Score SER model: {:.3f}'.format(np.mean(score_ser)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6506518",
   "metadata": {},
   "source": [
    "#### Visualization of decision trees :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions used for DT visualization\n",
    "\n",
    "def is_same_node(tree1,tree2,node1,node2):\n",
    "\n",
    "    if (node1 == -1 or node2 == -1):\n",
    "        return False\n",
    "    if tree1.tree_.feature[node1] != tree2.tree_.feature[node2]:\n",
    "        return False\n",
    "    if tree1.tree_.threshold[node1] != tree2.tree_.threshold[node2]:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def highlight_different_nodes(tree1,tree2,node1,node2):\n",
    "    \n",
    "    list_nodes1 = []\n",
    "    list_nodes2 = []\n",
    "    \n",
    "    if is_same_node(tree1,tree2,node1,node2) :\n",
    "        left1 = tree1.tree_.children_left[node1]\n",
    "        right1 = tree1.tree_.children_right[node1]\n",
    "        left2 = tree2.tree_.children_left[node2]\n",
    "        right2 = tree2.tree_.children_right[node2]\n",
    "        nl1, nl2 = highlight_different_nodes(tree1,tree2,left1,left2)\n",
    "        nr1, nr2 = highlight_different_nodes(tree1,tree2,right1,right2)\n",
    "        \n",
    "        list_nodes1 = list_nodes1 + nl1 + nr1\n",
    "        list_nodes2 = list_nodes2 + nl2 + nr2\n",
    "    else:        \n",
    "        list_nodes1 = list_nodes1 + ut.sub_nodes(tree1.tree_, node1)\n",
    "        list_nodes2 = list_nodes2 + ut.sub_nodes(tree2.tree_, node2)\n",
    "        \n",
    "    return list_nodes1, list_nodes2\n",
    "    \n",
    "class TreeDot():\n",
    "    def __init__(self,name_file,path=''):\n",
    "        self.nodes = list()\n",
    "        self.path = path\n",
    "        self.path_file = path+name_file\n",
    "        f = open(self.path_file,\"r\")\n",
    "        self.lines = f.readlines()\n",
    "        for line in self.lines :\n",
    "            start = line.split(' ')[0]\n",
    "            \n",
    "            if start.isnumeric():\n",
    "                self.nodes.append(int(start))\n",
    "                \n",
    "        self.nodes = set(self.nodes)\n",
    "        \n",
    "        self.leaves = self._list_leaves()\n",
    "        f.close()\n",
    "        \n",
    "    def _find_node(self,id_node):\n",
    "        ans = -1\n",
    "\n",
    "        #f = open(self.path_file,\"r\")\n",
    "        #lines = f.readlines()\n",
    "        for k,line in enumerate(self.lines) :\n",
    "            if str(id_node)==line.split(' [')[0] :\n",
    "            #if line[0:3] == (str(id_node)+ ' [') :\n",
    "                ans = k\n",
    "        return ans\n",
    "            \n",
    "    def _check_keyword(self,id_nodes,keyword):\n",
    "        checks = np.zeros(len(id_nodes))\n",
    "\n",
    "        #f = open(self.path_file,\"r\")\n",
    "        #lines = f.readlines()\n",
    "\n",
    "        for j,i in enumerate(id_nodes):\n",
    "            id_l = self._find_node(i) \n",
    "            if (' '+keyword) in self.lines[id_l]:\n",
    "                checks[j] = True\n",
    "            else:\n",
    "                checks[j] = False\n",
    "                \n",
    "        return checks\n",
    "            \n",
    "    def _change_color(self,id_nodes,color_,keyword,out_file=None):\n",
    "        if out_file is not None:\n",
    "            f = open(self.path+out_file,\"w+\")\n",
    "        else:             \n",
    "            f = open(self.path_file,\"r+\")\n",
    "            \n",
    "        #f_init = open(self.path_file,\"r\")\n",
    "        #lines = f_init.readlines()\n",
    "        new_lines = self.lines.copy()\n",
    "        \n",
    "        checks = self._check_keyword(id_nodes,keyword)\n",
    "            \n",
    "        for j,i in enumerate(id_nodes):\n",
    "            id_l = self._find_node(i)\n",
    "            \n",
    "            if checks[j]:\n",
    "                s_c = new_lines[id_l].split(keyword+'=\"')[1]\n",
    "                s_c = s_c.split('\"')[0]\n",
    "                \n",
    "                new_lines[id_l] = new_lines[id_l].replace(s_c,color_)\n",
    "            else:\n",
    "                new_lines[id_l] = new_lines[id_l].replace('] ;',' '+keyword+'=\"'+color_+'\"] ;')\n",
    "\n",
    "        f.writelines(s + '\\n' for s in new_lines)\n",
    "        #f_init.close()\n",
    "        #self.lines = f.readlines()\n",
    "        f.close()\n",
    "    \n",
    "    def _add_attribute(self,id_nodes,keyword,value,out_file=None):\n",
    "        if out_file is not None:\n",
    "            f = open(self.path+out_file,\"w+\")\n",
    "        else:             \n",
    "            f = open(self.path_file,\"r+\")\n",
    "            \n",
    "        #f_init = open(self.path_file,\"r\")\n",
    "        #lines = f_init.readlines()\n",
    "        new_lines = self.lines.copy()\n",
    "        for j,i in enumerate(id_nodes):\n",
    "            id_l = self._find_node(i)\n",
    "\n",
    "            new_lines[id_l] = new_lines[id_l].replace('] ;',' '+keyword+'='+str(value)+'] ;')\n",
    "\n",
    "        f.writelines(s + '\\n' for s in new_lines)\n",
    "        #f_init.close()\n",
    "        #self.lines = f.readlines()\n",
    "        f.close()     \n",
    "        \n",
    "    def _extract_node_info(self,id_):\n",
    "        attributes = []\n",
    "        values= []\n",
    "        \n",
    "        id_l = self._find_node(id_)\n",
    "        \n",
    "        line = self.lines[id_l]\n",
    "        infos = line.split('label=\"')[1].split('\"')[0]\n",
    "        list_infos = infos.split('\\n')\n",
    "        \n",
    "        for l in list_infos:\n",
    "            attributes.append(l.split(' = ')[0])\n",
    "            values.append(l.split(' = ')[1])\n",
    "        return attributes, values\n",
    "    \n",
    "    def _write_node_info(self,id_,attr,v):\n",
    "        f = open(self.path_file,\"r+\")\n",
    "\n",
    "        id_l = self._find_node(id_)        \n",
    "        line = self.lines[id_l]        \n",
    "        f.close()\n",
    "        \n",
    "    def _is_leaf(self,id_):\n",
    "        \n",
    "        attr,v = self._extract_node_info(id_)\n",
    "        if 'X' in attr[0]:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    def _list_leaves(self):\n",
    "        leaves = []\n",
    "        for n in self.nodes:\n",
    "            if self._is_leaf(n):\n",
    "                leaves.append(n)\n",
    "        return leaves\n",
    "            \n",
    "    def _format_leaves(self):\n",
    "        self._add_attribute(self.leaves,'shape','ellipse',out_file=None)\n",
    "            \n",
    "        \n",
    "    def _change_fillcolor(self,id_nodes,color_,out_file=None):\n",
    "        if out_file is not None:\n",
    "            f = open(self.path+out_file,\"w+\")\n",
    "        else:             \n",
    "            f = open(self.path_file,\"r+\")\n",
    "            \n",
    "        f_init = open(self.path_file,\"r\")\n",
    "        lines = f_init.readlines()\n",
    "        new_lines = lines.copy()\n",
    "        \n",
    "        checks = self._check_keyword(id_nodes,'fillcolor')\n",
    "            \n",
    "        for j,i in enumerate(id_nodes):\n",
    "            id_l = self._find_node(i)\n",
    "            \n",
    "            if checks[j]:\n",
    "                s_c = new_lines[id_l].split('fillcolor=\"')[1]\n",
    "                s_c = s_c.split('\"')[0]\n",
    "                \n",
    "                new_lines[id_l] = new_lines[id_l].replace(s_c,color_)\n",
    "            else:\n",
    "                new_lines[id_l] = new_lines[id_l].replace('] ;',' fillcolor=\"'+color_+'\"] ;')\n",
    "\n",
    "        f.writelines(s + '\\n' for s in new_lines)\n",
    "        f_init.close()\n",
    "        f.close()\n",
    "        \n",
    "    def _change_edgecolor(self,id_nodes,color_,out_file=None):\n",
    "        if out_file is not None:\n",
    "            f = open(self.path+out_file,\"w+\")\n",
    "        else:             \n",
    "            f = open(self.path_file,\"r+\")\n",
    "            \n",
    "        f_init = open(self.path_file,\"r\")    \n",
    "        lines = f_init.readlines()\n",
    "        new_lines = lines.copy()\n",
    "        checks = self._check_keyword(id_nodes,'color')\n",
    "            \n",
    "        for j,i in enumerate(id_nodes):\n",
    "            id_l = self._find_node(i)\n",
    "            \n",
    "            if checks[j]:\n",
    "                s_c = new_lines[id_l].split('color=\"')[1]\n",
    "                s_c = s_c.split('\"')[0]\n",
    "                \n",
    "                new_lines[id_l] = new_lines[id_l].replace(s_c,color_)\n",
    "            else:\n",
    "                new_lines[id_l] = new_lines[id_l].replace('] ;',' color=\"'+color_+'\"] ;')\n",
    "\n",
    "        f.writelines(s + '\\n' for s in new_lines)\n",
    "        f_init.close()\n",
    "        f.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a9f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz as exp_draw\n",
    "from matplotlib import image\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "your_path = ''\n",
    "\n",
    "file_out = exp_draw(clf_source,out_file=your_path+'tree_src.dot',filled=True,impurity=False)\n",
    "file_out = exp_draw(ser_model.estimator_,out_file=your_path+'tree_ser.dot',filled=True,impurity=False)\n",
    "file_out = exp_draw(strut_model.estimator_,out_file=your_path+'tree_strut.dot',filled=True,impurity=False)\n",
    "\n",
    "os.system('dot -Tpng '+your_path+'tree_src.dot -o '+your_path+'tree_src.png')\n",
    "os.system('dot -Tpng '+your_path+'tree_ser.dot -o '+your_path+'tree_ser.png')\n",
    "os.system('dot -Tpng '+your_path+'tree_strut.dot -o '+your_path+'tree_strut.png')\n",
    "\n",
    "tree_img = image.imread('tree_src.png')\n",
    "tree_ser_img = image.imread('tree_ser.png')\n",
    "tree_strut_img = image.imread('tree_strut.png')\n",
    "#plt.imshow(tree_img)\n",
    "#plt.imshow(tree_t_img)\n",
    "\n",
    "l1,l2 = highlight_different_nodes(clf_source,ser_model.estimator_,0,0)\n",
    "print(l1)\n",
    "print(l2)\n",
    "T_D_src = TreeDot('tree_src.dot',your_path)\n",
    "T_D_ser = TreeDot('tree_ser.dot',your_path)\n",
    "T_D_strut = TreeDot('tree_strut.dot',your_path)\n",
    "\n",
    "\n",
    "T_D_src._change_color(l1,'red','color',out_file='tree_src_updated.dot')\n",
    "T_D_src = TreeDot('tree_src_updated.dot',your_path)\n",
    "T_D_src._add_attribute(l1,'penwidth',3,out_file='tree_src_updated.dot')\n",
    "\n",
    "T_D_ser._change_color(l2,'red','color',out_file='tree_ser_updated.dot')\n",
    "T_D_ser = TreeDot('tree_ser_updated.dot',your_path)\n",
    "T_D_ser._add_attribute(l2,'penwidth',3,out_file='tree_ser_updated.dot')\n",
    "\n",
    "T_D_strut._change_color(l2,'red','color',out_file='tree_strut_updated.dot')\n",
    "T_D_strut = TreeDot('tree_strut_updated.dot',your_path)\n",
    "T_D_strut._add_attribute(l2,'penwidth',3,out_file='tree_strut_updated.dot')\n",
    "\n",
    "os.system('dot -Tpng '+your_path+'tree_src_updated.dot -o '+your_path+'tree_src_h.png')\n",
    "os.system('dot -Tpng '+your_path+'tree_ser_updated.dot -o '+your_path+'tree_ser_h.png')\n",
    "os.system('dot -Tpng '+your_path+'tree_strut_updated.dot -o '+your_path+'tree_strut_h.png')\n",
    "\n",
    "tree_src = image.imread(your_path+'tree_src_h.png')\n",
    "tree_ser = image.imread(your_path+'tree_ser_h.png')\n",
    "tree_strut = image.imread(your_path+'tree_strut_h.png')\n",
    "\n",
    "plt.imshow(tree_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db2611",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tree_ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a882943",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tree_strut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce38b1f",
   "metadata": {},
   "source": [
    "### Adding and deleting clusters between Source and Target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24af696",
   "metadata": {},
   "source": [
    "### Question 2.3 :\n",
    "\n",
    "Execute same previous steps on this new Source/Target transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bc9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "N0=5\n",
    "N1=5\n",
    "\n",
    "Xs,ys=generate_samples(100,means_src,sigs_src,classes_src)\n",
    "\n",
    "#Adding and deleting clusters:\n",
    "means,sigs,classes = delete_N_clusters(4,means_src,sigs_src,classes_src,mean_range=[-5,5],sig_range=[0.5,2])\n",
    "\n",
    "means,sigs,classes = add_N_clusters(2,0,means,sigs,classes,mean_range=[-5,5],sig_range=[0.5,2])\n",
    "means,sigs,classes = add_N_clusters(2,1,means,sigs,classes,mean_range=[-5,5],sig_range=[0.5,2])\n",
    "\n",
    "Xt,yt=generate_samples(100,means,sigs,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c0216",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(6, 3))\n",
    "ax[0].scatter(Xs[np.where(ys==0)[0], 0], Xs[np.where(ys==0)[0], 1],marker='o',edgecolor='black',color='blue',label='class 0')\n",
    "ax[0].scatter(Xs[np.where(ys==1)[0], 0], Xs[np.where(ys==1)[0], 1],marker='o',edgecolor='black',color='red',label='class 1')\n",
    "ax[0].set_title('Source data')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].scatter(Xt[np.where(yt==0)[0], 0], Xt[np.where(yt==0)[0], 1],marker='o',edgecolor='black',color='blue',label='class 0')\n",
    "ax[1].scatter(Xt[np.where(yt==1)[0], 0], Xt[np.where(yt==1)[0], 1],marker='o',edgecolor='black',color='red',label='class 1')\n",
    "ax[1].set_title('Target data')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c994f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_source_by_c = 50\n",
    "n_target_by_c = 10\n",
    "\n",
    "Xs,ys=generate_samples(n_source_by_c,means_src,sigs_src,classes_src)\n",
    "#Adding and deleting clusters:\n",
    "means,sigs,classes = delete_N_clusters(4,means_src,sigs_src,classes_src,mean_range=[-5,5],sig_range=[0.5,2])\n",
    "\n",
    "means,sigs,classes = add_N_clusters(2,0,means,sigs,classes,mean_range=[-5,5],sig_range=[0.5,2])\n",
    "means,sigs,classes = add_N_clusters(2,1,means,sigs,classes,mean_range=[-5,5],sig_range=[0.5,2])\n",
    "Xt,yt=generate_samples(n_target_by_c,means,sigs,classes)\n",
    "\n",
    "MAX = 5\n",
    "K_FOLD = 10\n",
    "\n",
    "# Source and Target classifiers :\n",
    "clf_source = DecisionTreeClassifier(max_depth=MAX)\n",
    "clf_target = DecisionTreeClassifier(max_depth=MAX)\n",
    "\n",
    "\n",
    "#K folds coss-validation:\n",
    "skf = select.StratifiedKFold(n_splits=K_FOLD)\n",
    "\n",
    "score_src = np.zeros(K_FOLD)\n",
    "score_src_tgt = np.zeros(K_FOLD)\n",
    "score_tgt_src = np.zeros(K_FOLD)\n",
    "score_tgt = np.zeros(K_FOLD)\n",
    "\n",
    "\"\"\"\n",
    "#.....................\n",
    "\"\"\"\n",
    "\n",
    "print('Score Target model: {:.3f}'.format(np.mean(score_tgt)))\n",
    "print('Score Source model: {:.3f}'.format(np.mean(score_src)))\n",
    "print('Score Source model on Target: {:.3f}'.format(np.mean(score_src_tgt)))\n",
    "#print('Score Target model on Source: {:.3f}'.format(np.mean(score_tgt_src)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed2394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_src = copy.deepcopy(clf_source)\n",
    "\n",
    "strut_model = TransferTreeClassifier(estimator=clf_src,algo=\"strut\")\n",
    "ser_model = TransferTreeClassifier(estimator=clf_src,algo=\"ser\")\n",
    "\n",
    "score_strut= np.zeros(K_FOLD)\n",
    "score_ser = np.zeros(K_FOLD)\n",
    "\n",
    "k=0\n",
    "\"\"\"\n",
    "#.....................\n",
    "\"\"\"\n",
    "\n",
    "print('Score STRUT model: {:.3f}'.format(np.mean(score_strut)))\n",
    "print('Score SER model: {:.3f}'.format(np.mean(score_ser)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d4867",
   "metadata": {},
   "source": [
    "#### Visualization of decision trees :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b70aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_path = ''\n",
    "\n",
    "file_out = exp_draw(clf_source,out_file=your_path+'tree_src.dot',filled=True,impurity=False)\n",
    "file_out = exp_draw(ser_model.estimator_,out_file=your_path+'tree_ser.dot',filled=True,impurity=False)\n",
    "file_out = exp_draw(strut_model.estimator_,out_file=your_path+'tree_strut.dot',filled=True,impurity=False)\n",
    "\n",
    "os.system('dot -Tpng '+your_path+'tree_src.dot -o '+your_path+'tree_src.png')\n",
    "os.system('dot -Tpng '+your_path+'tree_ser.dot -o '+your_path+'tree_ser.png')\n",
    "os.system('dot -Tpng '+your_path+'tree_strut.dot -o '+your_path+'tree_strut.png')\n",
    "\n",
    "tree_img = image.imread('tree_src.png')\n",
    "tree_ser_img = image.imread('tree_ser.png')\n",
    "tree_strut_img = image.imread('tree_strut.png')\n",
    "#plt.imshow(tree_img)\n",
    "#plt.imshow(tree_t_img)\n",
    "\n",
    "l1,l2 = highlight_different_nodes(clf_source,ser_model.estimator_,0,0)\n",
    "print(l1)\n",
    "print(l2)\n",
    "T_D_src = TreeDot('tree_src.dot',your_path)\n",
    "T_D_ser = TreeDot('tree_ser.dot',your_path)\n",
    "T_D_strut = TreeDot('tree_strut.dot',your_path)\n",
    "\n",
    "\n",
    "T_D_src._change_color(l1,'red','color',out_file='tree_src_updated.dot')\n",
    "T_D_src = TreeDot('tree_src_updated.dot',your_path)\n",
    "T_D_src._add_attribute(l1,'penwidth',3,out_file='tree_src_updated.dot')\n",
    "\n",
    "T_D_ser._change_color(l2,'red','color',out_file='tree_ser_updated.dot')\n",
    "T_D_ser = TreeDot('tree_ser_updated.dot',your_path)\n",
    "T_D_ser._add_attribute(l2,'penwidth',3,out_file='tree_ser_updated.dot')\n",
    "\n",
    "T_D_strut._change_color(l2,'red','color',out_file='tree_strut_updated.dot')\n",
    "T_D_strut = TreeDot('tree_strut_updated.dot',your_path)\n",
    "T_D_strut._add_attribute(l2,'penwidth',3,out_file='tree_strut_updated.dot')\n",
    "\n",
    "os.system('dot -Tpng '+your_path+'tree_src_updated.dot -o '+your_path+'tree_src_h.png')\n",
    "os.system('dot -Tpng '+your_path+'tree_ser_updated.dot -o '+your_path+'tree_ser_h.png')\n",
    "os.system('dot -Tpng '+your_path+'tree_strut_updated.dot -o '+your_path+'tree_strut_h.png')\n",
    "\n",
    "tree_src = image.imread(your_path+'tree_src_h.png')\n",
    "tree_ser = image.imread(your_path+'tree_ser_h.png')\n",
    "tree_strut = image.imread(your_path+'tree_strut_h.png')\n",
    "\n",
    "plt.imshow(tree_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4208b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tree_ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5408a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tree_strut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69b6b2c",
   "metadata": {},
   "source": [
    "### Question 2.4 : Compare SER/STRUT results on these two different transfer situations\n",
    "\n",
    "Why SER seems to outperform STRUT on both of them ?\n",
    "\n",
    "How can you explain that based on visualization of transferred decision trees ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06a2120",
   "metadata": {},
   "source": [
    "<h2>Exercise 3 : Transfer learning on Random Forests (on fall detection data)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf7204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapt.parameter_based import TransferTreeClassifier, TransferForestClassifier\n",
    "import copy\n",
    "from adapt.base import BaseAdaptEstimator\n",
    "from adapt.utils import check_arrays, set_random_seed, check_estimator, check_fitted_estimator\n",
    "from sklearn.metrics import roc_auc_score as _auc_\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class TransferTreeSelector(BaseAdaptEstimator):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 estimator=None,\n",
    "                 Xt=None,\n",
    "                 yt=None,\n",
    "                 algorithms=list(),\n",
    "                 copy=True,\n",
    "                 verbose=1,\n",
    "                 random_state=None,\n",
    "                 **params):\n",
    "               \n",
    "        if not hasattr(estimator, \"tree_\"):\n",
    "            raise ValueError(\"`estimator` argument has no ``tree_`` attribute, \"\n",
    "                                \"please call `fit` on `estimator` or use \"\n",
    "                                \"another estimator as `DecisionTreeClassifier`.\")\n",
    "        \n",
    "        estimator = check_fitted_estimator(estimator)\n",
    "        \n",
    "        super().__init__(estimator=estimator,\n",
    "                         Xt=Xt,\n",
    "                         yt=yt,\n",
    "                         copy=copy,\n",
    "                         verbose=verbose,                       \n",
    "                         **params)\n",
    "\n",
    "        \n",
    "        if len(algorithms) == 0:\n",
    "            print('Warning : empty list of methods. Default are Source and Target models.')\n",
    "            self.algorithms = ['src','trgt']\n",
    "        else:\n",
    "            self.algorithms = algorithms\n",
    "        \n",
    "        self.n_methods = len(self.algorithms)\n",
    "        self.scores = np.zeros(self.n_methods)\n",
    "        \n",
    "        self.best_score = 0\n",
    "        self.best_index = -1\n",
    "        \n",
    "        self.transferred_models = list()\n",
    "        \n",
    "        for algo in self.algorithms:\n",
    "            self.transferred_models.append(TransferTreeClassifier(estimator=self.estimator,Xt=self.Xt,yt=self.yt,algo=algo,copy=self.copy))\n",
    "            \n",
    "      \n",
    "    def fit(self, Xt=None, yt=None, **fit_params):\n",
    "        \n",
    "        Xt, yt = self._get_target_data(Xt, yt)\n",
    "        Xt, yt = check_arrays(Xt, yt)\n",
    "        set_random_seed(self.random_state)\n",
    "        \n",
    "        for k,algo in enumerate(self.algorithms):\n",
    "            self.transferred_models[k].fit(Xt=Xt, yt=yt,**fit_params)\n",
    "            \n",
    "    def select(self,Xtest=None,ytest=None,score_type=\"auc\"):\n",
    "        \n",
    "        Xtest, ytest = self._get_target_data(Xtest, ytest)\n",
    "        Xtest, ytest = check_arrays(Xtest, ytest)\n",
    "        set_random_seed(self.random_state)\n",
    "        \n",
    "        for k in range(len(self.algorithms)):\n",
    "            if score_type == \"auc\":\n",
    "                self.scores[k] = _auc_(ytest,self.transferred_models[k].estimator_.predict_proba(Xtest)[:,1]) \n",
    "            else:\n",
    "                self.scores[k] = self.transferred_models[k].score(Xtest,ytest) \n",
    "        \n",
    "        self.best_score = np.amax(self.scores)\n",
    "        self.best_index = np.argmax(self.scores)\n",
    "        self.best_method = self.algorithms[self.best_index]\n",
    "        \n",
    "        return self.best_score, self.best_index\n",
    "    \n",
    "\n",
    "class TransferForestSelector(BaseAdaptEstimator):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 estimator=None,\n",
    "                 Xt=None,\n",
    "                 yt=None,\n",
    "                 algorithms=list(),\n",
    "                 bootstrap=True,\n",
    "                 copy=True,\n",
    "                 verbose=1,\n",
    "                 random_state=None,\n",
    "                 **params):\n",
    "        \n",
    "        if not isinstance(estimator, RandomForestClassifier):\n",
    "            raise ValueError(\"`estimator` argument must be a ``RandomForestClassifier`` instance, got %s.\"%str(type(estimator)))\n",
    "\n",
    "        if not hasattr(estimator, \"estimators_\"):\n",
    "            raise ValueError(\"`estimator` argument has no ``estimators_`` attribute, \"\n",
    "                                \"please call `fit` on `estimator`.\")\n",
    "        \n",
    "        estimator = check_fitted_estimator(estimator)\n",
    "        \n",
    "        super().__init__(estimator=estimator,\n",
    "                         Xt=Xt,\n",
    "                         yt=yt,\n",
    "                         copy=copy,\n",
    "                         verbose=verbose,\n",
    "                         random_state=random_state,                       \n",
    "                         bootstrap=bootstrap,\n",
    "                         **params)\n",
    "        \n",
    "        self.estimator_ = check_estimator(self.estimator,\n",
    "                                          copy=self.copy,\n",
    "                                          force_copy=True)\n",
    "        \n",
    "        estimator = check_fitted_estimator(estimator)\n",
    "        \n",
    "        super().__init__(estimator=estimator,\n",
    "                         Xt=Xt,\n",
    "                         yt=yt,\n",
    "                         copy=copy,\n",
    "                         bootstrap=bootstrap,\n",
    "                         verbose=verbose,                       \n",
    "                         **params)\n",
    "\n",
    "        \n",
    "        if len(algorithms) == 0:\n",
    "            print('Warning : empty list of methods. Default are Source and Target models.')\n",
    "            self.algorithms = ['src','trgt']\n",
    "        else:\n",
    "            self.algorithms = algorithms\n",
    "        \n",
    "        self.rf_size = self.estimator_.n_estimators\n",
    "        \n",
    "        self.n_methods = len(self.algorithms)\n",
    "        self.scores = np.zeros(self.n_methods)\n",
    "        \n",
    "        self.best_score = 0\n",
    "        self.best_index = -1\n",
    "        \n",
    "        self.transferred_models = list()\n",
    "        \n",
    "        for algo in self.algorithms:\n",
    "            self.transferred_models.append(TransferForestClassifier(estimator=self.estimator,Xt=self.Xt,yt=self.yt,algo=algo,bootstrap=self.bootstrap,copy=self.copy))\n",
    "            \n",
    "        self.STRF_model = TransferForestClassifier(estimator=self.estimator,Xt=self.Xt,yt=self.yt,algo=algo,bootstrap=self.bootstrap,copy=self.copy)\n",
    "        self.STRF_indexes = np.zeros(self.rf_size)\n",
    "        \n",
    "    def model_selection(self, Xt=None, yt=None, score_type = \"auc\", oob_ = False, **fit_params):\n",
    "        \n",
    "        Xt, yt = self._get_target_data(Xt, yt)\n",
    "        Xt, yt = check_arrays(Xt, yt)\n",
    "        set_random_seed(self.random_state)\n",
    "        \n",
    "        rf_out = copy.deepcopy(self.estimator)\n",
    "        \n",
    "        for k in range(self.rf_size):\n",
    "            #TTS = TransferTreeSelector(estimator=self.STRF_model.estimator_.estimators_[k],algorithms=self.algorithms)\n",
    "            TTS = TransferTreeSelector(estimator=self.estimator_.estimators_[k],algorithms=self.algorithms)\n",
    "            \n",
    "            if self.bootstrap:\n",
    "                inds, oob_inds = ut._bootstrap_(yt.size,class_wise=True,y=yt)\n",
    "                TTS.fit(Xt[inds],yt[inds])                \n",
    "                if oob_:\n",
    "                    score, index = TTS.select(Xtest=Xt[oob_inds],ytest=yt[oob_inds],score_type=score_type)\n",
    "                else:\n",
    "                    score, index = TTS.select(Xtest=Xt[inds],ytest=yt[inds],score_type=score_type)\n",
    "            else:\n",
    "                TTS.fit(Xt,yt)                \n",
    "                score, index = TTS.select(Xtest=Xt,ytest=yt,score_type=score_type)                 \n",
    "\n",
    "            self.STRF_indexes[k] = index\n",
    "            \n",
    "            self.STRF_model.estimators_[k] = TTS.transferred_models[index]\n",
    "            \n",
    "            for j,m in enumerate(self.transferred_models):\n",
    "                #rf_out_alg = copy.deepcopy(rf_out)\n",
    "                m.estimators_[k] = TTS.transferred_models[j]\n",
    "                m.estimator_.estimators_[k] = TTS.transferred_models[j].estimator_\n",
    "                #m.estimator_ = rf_out_alg\n",
    "                \n",
    "            rf_out.estimators_[k] = TTS.transferred_models[index].estimator_\n",
    "        \n",
    "        self.STRF_model.estimator_ = rf_out\n",
    "        self.estimator_ = rf_out\n",
    "        \n",
    "        return self.STRF_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8565274a",
   "metadata": {},
   "source": [
    "<h3>1. Balanced data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc28b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save = ''\n",
    "\n",
    "name_bdd_sim = 'bdd_sim_test_ech5_win250_marg50.csv'\n",
    "name_bdd_real = 'bdd_realfalls_test_ech1_win250_marg5.csv'\n",
    "\n",
    "M_sim = pd.read_csv(path_save+name_bdd_sim)\n",
    "names = np.array(M_sim['fname'])\n",
    "Y_source = np.array(M_sim['Label'])\n",
    "X_source = np.array(M_sim.iloc[:,1:-2]).astype('float32')\n",
    "\n",
    "M_real = pd.read_csv(path_save+name_bdd_real)\n",
    "names = np.array(M_real['fname'])\n",
    "Y_target = np.array(M_real['Label'])\n",
    "X_target = np.array(M_real.iloc[:,1:-2]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e206f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_only = False\n",
    "K_FOLD = 5\n",
    "MAX = 5\n",
    "RF_SIZE = 10\n",
    "n_ech_src = 5\n",
    "n_ech_tgt = 1\n",
    "\n",
    "list_feats = np.arange(0,10,1)\n",
    "\n",
    "X_source = X_source[::n_ech_src,list_feats] \n",
    "Y_source = Y_source[::n_ech_src] \n",
    "X_target = X_target[::n_ech_tgt,list_feats]\n",
    "Y_target = Y_target[::n_ech_tgt]\n",
    "\n",
    "# Source classifier\n",
    "if DT_only:\n",
    "    clf_source = DecisionTreeClassifier(max_depth=MAX)\n",
    "    clf_target = DecisionTreeClassifier(max_depth=MAX)\n",
    "else:\n",
    "    clf_source = RandomForestClassifier(n_estimators=RF_SIZE,max_depth=MAX)\n",
    "    clf_target = RandomForestClassifier(n_estimators=RF_SIZE,max_depth=MAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dfb4a5",
   "metadata": {},
   "source": [
    "### Question 1.1 :\n",
    "\n",
    "Train two Random Forests (source and target) and assess them both on source and target using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8830ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = select.StratifiedKFold(n_splits=K_FOLD)\n",
    "\n",
    "score_src = np.zeros(K_FOLD)\n",
    "score_src_tgt = np.zeros(K_FOLD)\n",
    "score_tgt_src = np.zeros(K_FOLD)\n",
    "score_tgt = np.zeros(K_FOLD)\n",
    "\n",
    "auc_score_src = np.zeros(K_FOLD)\n",
    "auc_score_src_tgt = np.zeros(K_FOLD)\n",
    "auc_score_tgt_src = np.zeros(K_FOLD)\n",
    "auc_score_tgt = np.zeros(K_FOLD)\n",
    "\n",
    "tpr_roc_src = np.zeros(K_FOLD,dtype=object)\n",
    "tpr_roc_tgt = np.zeros(K_FOLD,dtype=object)\n",
    "tpr_roc_src_tgt = np.zeros(K_FOLD,dtype=object)\n",
    "tpr_roc_tgt_src = np.zeros(K_FOLD,dtype=object)\n",
    "fpr_roc_src = np.zeros(K_FOLD,dtype=object)\n",
    "fpr_roc_tgt = np.zeros(K_FOLD,dtype=object)\n",
    "fpr_roc_src_tgt = np.zeros(K_FOLD,dtype=object)\n",
    "fpr_roc_tgt_src = np.zeros(K_FOLD,dtype=object)\n",
    "th_roc_src = np.zeros(K_FOLD,dtype=object)\n",
    "th_roc_tgt = np.zeros(K_FOLD,dtype=object)\n",
    "th_roc_src_tgt = np.zeros(K_FOLD,dtype=object)\n",
    "th_roc_tgt_src = np.zeros(K_FOLD,dtype=object)\n",
    "\n",
    "\n",
    "k=0\n",
    "for train, test in skf.split(X_source, Y_source):\n",
    "    X_src_train, Y_src_train, X_src_test, Y_src_test = X_source[train], Y_source[train], X_source[test], Y_source[test]\n",
    "    clf_source.fit(X_src_train, Y_src_train)\n",
    "    score_src[k] = clf_source.score(X_src_test, Y_src_test)\n",
    "    score_src_tgt[k] = clf_source.score(X_target, Y_target)\n",
    "    auc_score_src[k] = metr.roc_auc_score(Y_src_test,clf_source.predict_proba(X_src_test)[:,1])\n",
    "    auc_score_src_tgt[k] = metr.roc_auc_score(Y_target,clf_source.predict_proba(X_target)[:,1])\n",
    "    \n",
    "    fpr_roc_src[k],tpr_roc_src[k],th_roc_src[k] = metr.roc_curve(Y_src_test,clf_source.predict_proba(X_src_test)[:,1])\n",
    "    fpr_roc_src_tgt[k],tpr_roc_src_tgt[k],th_roc_src_tgt[k] = metr.roc_curve(Y_target,clf_source.predict_proba(X_target)[:,1])\n",
    "    \n",
    "    k+=1\n",
    "\n",
    "k=0\n",
    "for train, test in skf.split(X_target, Y_target):\n",
    "    X_tgt_train, Y_tgt_train, X_tgt_test, Y_tgt_test = X_target[train], Y_target[train], X_target[test], Y_target[test]\n",
    "    clf_target.fit(X_tgt_train, Y_tgt_train)\n",
    "    score_tgt[k] = clf_target.score(X_tgt_test, Y_tgt_test)\n",
    "    score_tgt_src[k] = clf_target.score(X_source, Y_source)\n",
    "    auc_score_tgt[k] = metr.roc_auc_score(Y_tgt_test,clf_target.predict_proba(X_tgt_test)[:,1])\n",
    "    auc_score_tgt_src[k] = metr.roc_auc_score(Y_source,clf_target.predict_proba(X_source)[:,1])\n",
    "    \n",
    "    fpr_roc_tgt[k],tpr_roc_tgt[k],th_roc_tgt[k] = metr.roc_curve(Y_tgt_test,clf_target.predict_proba(X_tgt_test)[:,1])\n",
    "    fpr_roc_tgt_src[k],tpr_roc_tgt_src[k],th_roc_tgt_src[k]  = metr.roc_curve(Y_source,clf_target.predict_proba(X_source)[:,1])\n",
    " \n",
    "    k+=1\n",
    "    \n",
    "print('Score Target model: {:.3f}'.format(np.mean(score_tgt)))\n",
    "print('Score Source model: {:.3f}'.format(np.mean(score_src)))\n",
    "print('Score Source model on Target: {:.3f}'.format(np.mean(score_src_tgt)))\n",
    "print('Score Target model on Source: {:.3f}'.format(np.mean(score_tgt_src)))\n",
    "\n",
    "print('ROC AUC Target model: {:.3f}'.format(np.mean(auc_score_tgt)))\n",
    "print('ROC AUC Source model: {:.3f}'.format(np.mean(auc_score_src)))\n",
    "print('ROC AUC Source model on Target: {:.3f}'.format(np.mean(auc_score_src_tgt)))\n",
    "print('ROC AUC Target model on Source: {:.3f}'.format(np.mean(auc_score_tgt_src)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476f8149",
   "metadata": {},
   "source": [
    "### Question 1.2 :\n",
    "\n",
    "Plot four ROC curves corresponding to each situation.\n",
    "Why does this motivate a transfer learning approach ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beb8e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_list = ['src','trgt','relab','ser','strut']\n",
    "n_versions = len(algo_list)\n",
    "\n",
    "auc_score_strf = np.zeros(K_FOLD)\n",
    "auc_score_strut = np.zeros(K_FOLD)\n",
    "auc_score_ser = np.zeros(K_FOLD)\n",
    "auc_score_strf_src = np.zeros(K_FOLD)\n",
    "auc_score_strut_src = np.zeros(K_FOLD)\n",
    "auc_score_ser_src = np.zeros(K_FOLD)\n",
    "\n",
    "score_strf = np.zeros(K_FOLD)\n",
    "score_strut = np.zeros(K_FOLD)\n",
    "score_ser = np.zeros(K_FOLD)\n",
    "\n",
    "count_ind = np.zeros((K_FOLD,n_versions))\n",
    "\n",
    "k=0\n",
    "for train, test in skf.split(X_target, Y_target):\n",
    "    X_tgt_train, Y_tgt_train, X_tgt_test, Y_tgt_test = X_target[train], Y_target[train], X_target[test], Y_target[test]\n",
    "\n",
    "    if DT_only:\n",
    "        TTS = TransferTreeSelector(estimator=clf_source,algorithms=algo_list)\n",
    "        TTS.fit(X_tgt_train,Y_tgt_train)\n",
    "        strut_model = TTS.transferred_models[algo_list.index(\"strut\")]\n",
    "        ser_model = TTS.transferred_models[algo_list.index(\"ser\")]\n",
    "        \n",
    "        score_strut[k] = strut_model.score(X_tgt_test,Y_tgt_test) \n",
    "        score_ser[k] = ser_model.score(X_tgt_test,Y_tgt_test) \n",
    "        \n",
    "        #print(TTS.select(X_tgt_test, Y_tgt_test))\n",
    "    else:\n",
    "        TFS = TransferForestSelector(estimator=clf_source,algorithms=algo_list)\n",
    "        TFS.model_selection(X_tgt_train,Y_tgt_train,score_type=\"auc\",oob_=True)\n",
    "        score_strf[k] = TFS.STRF_model.score(X_tgt_test,Y_tgt_test) \n",
    "         \n",
    "        strut_model = TFS.transferred_models[algo_list.index(\"strut\")]\n",
    "        ser_model = TFS.transferred_models[algo_list.index(\"ser\")]\n",
    "        \n",
    "        score_strut[k] = strut_model.score(X_tgt_test,Y_tgt_test) \n",
    "        score_ser[k] = ser_model.score(X_tgt_test,Y_tgt_test) \n",
    "        \n",
    "        auc_score_strf[k] = metr.roc_auc_score(Y_tgt_test,TFS.STRF_model.estimator_.predict_proba(X_tgt_test)[:,1])\n",
    "        auc_score_strut[k] = metr.roc_auc_score(Y_tgt_test,strut_model.estimator_.predict_proba(X_tgt_test)[:,1])\n",
    "        auc_score_ser[k] = metr.roc_auc_score(Y_tgt_test,ser_model.estimator_.predict_proba(X_tgt_test)[:,1])\n",
    "\n",
    "        auc_score_strf_src[k] = metr.roc_auc_score(Y_source,TFS.STRF_model.estimator_.predict_proba(X_source)[:,1])\n",
    "        auc_score_strut_src[k] = metr.roc_auc_score(Y_source,strut_model.estimator_.predict_proba(X_source)[:,1])\n",
    "        auc_score_ser_src[k] = metr.roc_auc_score(Y_source,ser_model.estimator_.predict_proba(X_source)[:,1])\n",
    "        \n",
    "        counts = np.zeros(n_versions)\n",
    "        for u in range(n_versions):\n",
    "            counts[u] = list(TFS.STRF_indexes).count(u)\n",
    "        count_ind[k] = counts/RF_SIZE  \n",
    "    k+=1\n",
    "\n",
    "print('SCORES:')\n",
    "print(np.mean(score_strut))\n",
    "print(np.mean(score_ser))\n",
    "print(np.mean(score_strf))\n",
    "print('AUC SCORES:')\n",
    "print(np.mean(auc_score_strut))\n",
    "print(np.mean(auc_score_ser))\n",
    "print(np.mean(auc_score_strf))\n",
    "print('AUC SCORES ON SRC:')\n",
    "print(np.mean(auc_score_strut_src))\n",
    "print(np.mean(auc_score_ser_src))\n",
    "print(np.mean(auc_score_strf_src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c7fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(count_ind, columns = algo_list)\n",
    "ax = sns.barplot(data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fafbb63",
   "metadata": {},
   "source": [
    "<h3>2. Imbalanced data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ff379",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save = ''\n",
    "\n",
    "name_bdd_sim = 'bdd_sim_test_ech5_win250_marg50.csv'\n",
    "name_bdd_real = 'IMB_bdd_realfalls_test_ech1_win250_marg5.csv'\n",
    "\n",
    "M_sim = pd.read_csv(path_save+name_bdd_sim)\n",
    "names = np.array(M_sim['fname'])\n",
    "Y_source = np.array(M_sim['Label'])\n",
    "X_source = np.array(M_sim.iloc[:,1:-2]).astype('float32')\n",
    "\n",
    "M_real = pd.read_csv(path_save+name_bdd_real)\n",
    "names = np.array(M_real['fname'])\n",
    "Y_target = np.array(M_real['Label'])\n",
    "X_target = np.array(M_real.iloc[:,1:-2]).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b65550",
   "metadata": {},
   "source": [
    "### (Bonus) Question 2 : Experiment every desired transfer algorithm on these new imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31477e02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
